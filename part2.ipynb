{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requisites\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from typing import Tuple, List\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "from gensim.models import fasttext\n",
    "from textsim_class import TextSimilarity\n",
    "import spacy\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2-cased-sts and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"projecte-aina/roberta-base-ca-v2\")\n",
    "roberta_model = AutoModel.from_pretrained('projecte-aina/roberta-base-ca-v2')\n",
    "roberta_model.eval()\n",
    "print(\"done\")\n",
    "model_finetuned = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "tokenizer_finetuned = AutoTokenizer.from_pretrained(model_finetuned)\n",
    "model_finetuned = AutoModel.from_pretrained(model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"projecte-aina/sts-ca\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from gensim.models import FastText\n",
    "import gensim\n",
    "# No funciona de moment\n",
    "model = gensim.models.fasttext.FastTextKeyedVectors.load('./models/fasttext/cc_ca_300.bin')\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = word2vec.Word2Vec.load(f\"./models/word2vec_10000_300_10_5.model\")\n",
    "wv_model = wv_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_1000 = word2vec.Word2Vec.load(f\"./models/cai/w2v_1000.model\")\n",
    "wv_model_1000 = wv_model_1000.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_500 = word2vec.Word2Vec.load(f\"./models/cai/w2v_500.model\")\n",
    "wv_model_500 = wv_model_500.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_100 = word2vec.Word2Vec.load(f\"./models/word2vec_100_3.model\")\n",
    "wv_model_100 = wv_model_100.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Word2vec permet dos formats: text i binari\n",
    "kv_model = KeyedVectors.load_word2vec_format('./models/word2vec/34/model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.load_facebook_model('./models/fasttext/cc.ca.300.bin.gz')\n",
    "ft_model = ft_model.wv\n",
    "\"\"\"\n",
    "Doesn't work\n",
    "from gensim.models import FastText\n",
    "ft_model = FastText.load('./models/fasttext/cc_ca_300.bin', mmap='r')\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spacy = spacy.load(\"ca_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_roberta = spacy.load(\"ca_core_news_trf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = [\n",
    "    # model     mode    pretr   cls remap   train   recalc  name\n",
    "    (wv_model, \"onehot\", True, True, True, True,True,  \"Onehot\"),\n",
    "    (wv_model, \"mean\",  True, True, True, True, True, \"Word2vec propi mean\"),\n",
    "    (wv_model, \"tfidf\",  True, True, True, True, True,\"Word2vec propi tfidf\"),\n",
    "    (wv_model_1000, \"mean\",  True, True, True, True, True, \"Word2vec 1000 mean\"),\n",
    "    (wv_model_1000, \"tfidf\",  True, True, True, True, True,\"Word2vec 1000 tfidf\"),\n",
    "    (wv_model_500, \"mean\",  True, True, True, True, True, \"Word2vec 500 mean\"),\n",
    "    (wv_model_500, \"tfidf\",  True, True, True, True, True,\"Word2vec 500 tfidf\"),\n",
    "    (wv_model_100, \"mean\",  True, True, True, True, True, \"Word2vec 100 mean\"),\n",
    "    (wv_model_100, \"tfidf\",  True, True, True, True, True,\"Word2vec 100 tfidf\"),\n",
    "    (kv_model, \"mean\",  True, True, True, True, True,\"Word2vec nlpl mean\"),\n",
    "    (kv_model, \"tfidf\",  True, True, True, True, True,\"Word2vec nlpl tfidf\"),\n",
    "    (ft_model, \"mean\",  True, True, True, True, True,\"Word2vec ccca300 mean\"),\n",
    "    (ft_model, \"tfidf\",  True, True, True, True, True,\"Word2vec ccca300 tfidf\"),\n",
    "    (model_spacy, \"spacy\",  True, True, True, True, True, \"Spacy md\"),\n",
    "    (model_roberta, \"roberta\", True, False, True, True, \"roberta_mean_mapped_pairs\", \"Roberta mean\"),\n",
    "    (model_roberta, \"roberta\", True, True, True, True, \"roberta_mapped_pairs\", \"Roberta cls\"),\n",
    "    (model_roberta, \"roberta2\", True, False, True, True, \"roberta2_mapped_pairs\", \"Roberta 0 mean\"),\n",
    "    (model_roberta, \"roberta2\", True, True, True, True, \"roberta2_cls_mapped_pairs\", \"Roberta 0 cls\"),\n",
    "    (roberta_model, \"roberta-hugging\", True, False, True, True, \"roberta-hugging_mean_mapped_pairs\", \"Roberta hugging mean\"),\n",
    "    (roberta_model, \"roberta-hugging\", True, True, True, True, \"roberta-hugging_cls_mapped_pairs\", \"Roberta hugging cls\"),\n",
    "    (model_finetuned, \"roberta-hugging\", True, False, True, True, \"roberta_finetuned_mean_mapped_pairs\", \"Roberta finetuned mean\"),\n",
    "    (model_finetuned, \"roberta-hugging\", True, True, True, True, \"roberta_finetuned_cls_mapped_pairs\", \"Roberta finetuned cls\"),\n",
    "    (wv_model, \"embeddings\", False, True, True, False, True, \"Random v2\"),\n",
    "    (wv_model, \"embeddings\", False, True, True, True, True, \"Random\"),\n",
    "    (wv_model, \"embeddings\", True, True, True, False, True, \"Initialized w2v propi notrain\"),\n",
    "    (wv_model, \"embeddings\", True, True, True, True, True, \"Initialized w2v propi\"),\n",
    "    (ft_model, \"embeddings\", True, True, True, False,True,  \"Initialized ccca300 notrain\"),\n",
    "    (ft_model, \"embeddings\", True, True, True, True, True, \"Initialized ccca300\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict: dict[str, dict[str, str|float|None]] = {\n",
    "    model_name + str(exec_model): {\n",
    "        'Model': model_name,\n",
    "        'Exec model': exec_model,\n",
    "        'Mode': None, \n",
    "        'Pretrained': None, \n",
    "        'CLS': None, \n",
    "        'Trained': None, \n",
    "        'Train pearson': None, \n",
    "        'Val pearson': None,\n",
    "        'Test pearson': None,\n",
    "        'Train spearman': None, \n",
    "        'Val spearman': None,\n",
    "        'Test spearman': None\n",
    "        \n",
    "        } for model_name in [l[-1] for l in list_of_models] for exec_model in range(9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = len(list_of_models)\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, it takes more than 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow model 1/8 done\n",
      "WARNING:tensorflow:From c:\\Users\\Usuario\\Documents\\Universitat\\4rt Quatri\\PLH\\Practica4\\word-embeddings\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "1 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "2 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "3 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "4 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "5 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "6 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "7 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "8 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "9 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "10 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "11 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "12 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "13 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "14 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "15 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "16 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "17 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "18 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "19 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "20 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "21 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "22 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "23 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "24 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "25 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "26 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "27 models done of a total of 28\n",
      "Tensorflow model 1/8 done\n",
      "Tensorflow model 2/8 done\n",
      "Tensorflow model 3/8 done\n",
      "Tensorflow model 4/8 done\n",
      "Tensorflow model 5/8 done\n",
      "Tensorflow model 6/8 done\n",
      "Tensorflow model 7/8 done\n",
      "Tensorflow model 8/8 done\n",
      "28 models done of a total of 28\n"
     ]
    }
   ],
   "source": [
    "for information in list_of_models:\n",
    "    model, mode, pretrained, cls, remap, trainable, recalculate, name = information\n",
    "\n",
    "    text_sim = TextSimilarity(model=model, dataset=dataset, mode=mode, pretrained=pretrained, cls=cls, remap=remap, trainable=trainable, recalculate=recalculate, dict_size=1000000)\n",
    "\n",
    "    text_sim.define_model(id=0)\n",
    "    train_pearson, val_pearson, test_pearson, train_spearman, val_spearman, test_spearman = text_sim.baseline_model()\n",
    "\n",
    "\n",
    "\n",
    "    results_dict[name + str(8)] = {\n",
    "                'Model': name,\n",
    "            'Exec model': \"Baseline\",\n",
    "            'Mode': mode, \n",
    "            'Pretrained': pretrained, \n",
    "            'CLS': cls, \n",
    "            'Trained': trainable, \n",
    "            'Train pearson': train_pearson, \n",
    "            'Val pearson': val_pearson,\n",
    "            'Test pearson': test_pearson,\n",
    "            'Train spearman': train_spearman, \n",
    "            'Val spearman': val_spearman,\n",
    "            'Test spearman': test_spearman\n",
    "        }\n",
    "    \n",
    "    for index in range(8):\n",
    "        text_sim.define_model(id=index)\n",
    "        train_pearson, val_pearson, test_pearson, train_spearman, val_spearman, test_spearman = text_sim.train(num_epochs=128)\n",
    "        results_dict[name + str(index)] = {\n",
    "                'Model': name,\n",
    "            'Exec model': str(index),\n",
    "            'Mode': mode, \n",
    "            'Pretrained': pretrained, \n",
    "            'CLS': cls, \n",
    "            'Trained': trainable, \n",
    "            'Train pearson': train_pearson, \n",
    "            'Val pearson': val_pearson,\n",
    "            'Test pearson': test_pearson,\n",
    "            'Train spearman': train_spearman, \n",
    "            'Val spearman': val_spearman,\n",
    "            'Test spearman': test_spearman\n",
    "        }\n",
    "        print(f\"Tensorflow model {index+1}/8 done\")\n",
    "    count += 1\n",
    "    print(f\"{count} models done of a total of {total_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to './results/similarity_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results_dict).T\n",
    "\n",
    "# Reorder the columns and sort the values by the 'Avg. Statistic' column\n",
    "results_df = results_df[['Model', 'Exec model', 'Mode', 'Pretrained', 'CLS', 'Trained', 'Train pearson', 'Val pearson', 'Test pearson', 'Train spearman', 'Val spearman', 'Test spearman']]\n",
    "results_df = results_df.sort_values(by='Test pearson', ascending=False)\n",
    "\n",
    "\n",
    "results_df.to_csv('./results/similarity_results.csv', index=False)\n",
    "print(f\"Results saved to './results/similarity_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def generate_model_barplot(results_df: pd.DataFrame, metric: str, model = \"all\") -> None:\n",
    "\t\"\"\"\n",
    "\tGenerate a barplot of the models evaluated for the given metric.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tresults_df : pd.DataFrame\n",
    "\t\tThe DataFrame containing the results of the evaluation.\n",
    "\tmetric : str\n",
    "\t\tThe metric to generate the barplot for. It can be one of ['Avg. Statistic', 'Pearson', 'Spearman', 'OOV Perc.'].\n",
    "\tfamily : str, optional\n",
    "\t\tThe family of models to generate the barplot for. It can be one of ['all', 'w2v', 'ft']. The default is 'all'.\n",
    "\t\"\"\"\n",
    "\tassert metric in ['Train pearson', 'Val pearson', 'Test pearson'], f\"Invalid metric '{metric}'. Must be one of ['Avg. Statistic', 'Pearson', 'Spearman', 'OOV Perc.'].\"\n",
    "\t# Filter the dataframe by the family of models\n",
    "\n",
    "\tif model != \"all\":\n",
    "\t\tresults_filtered_df = results_df[results_df['Exec model']==model].copy()\n",
    "\telse:\n",
    "\t\tresults_filtered_df = results_df.copy()\n",
    "\n",
    "\t# Sort the values by the metric (descending order, except for 'OOV Perc.')\n",
    "\tresults_filtered_df = results_filtered_df.sort_values(by=metric, ascending=(metric == 'OOV Perc.'))\n",
    "\n",
    "\t# Remove .model from the model names\n",
    "\tresults_filtered_df['Model'] = results_filtered_df['Model'].apply(lambda x: x.removesuffix('.model'))\n",
    "\n",
    "\t# Generate the barplot\n",
    "\tplt.figure(figsize=(10, 6))\n",
    "\tsns.barplot(x='Model', y=metric, data=results_filtered_df)\n",
    "\tplt.xticks(rotation=45, ha='right')\n",
    "\tplt.xlabel('Model')\n",
    "\tplt.ylabel(metric)\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f'./results/plots/textsim_{model}_{metric.lower().replace(\".\", \"\").replace(\" \", \"_\")}.png')\n",
    "\tplt.close()\n",
    "\n",
    "generate_model_barplot(results_df, \"Test pearson\", model=\"Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textsim_class\n",
    "reload(textsim_class)\n",
    "import textsim_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"projecte-aina/roberta-base-ca-v2\")\n",
    "roberta_model = AutoModel.from_pretrained('projecte-aina/roberta-base-ca-v2')\n",
    "roberta_model.eval()\n",
    "print(\"done\")\n",
    "model_finetuned = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "tokenizer_finetuned = AutoTokenizer.from_pretrained(model_finetuned)\n",
    "model_finetuned = AutoModel.from_pretrained(model_finetuned)\n",
    "model_finetuned.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = textsim_class.TextSimilarity(model=wv_model, dataset=dataset, mode=\"mean\", pretrained=False, cls=True, remap=True, trainable=True, tokenizer = tokenizer_finetuned, dict_size=1000000, recalculate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.define_model(id=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_997\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_997\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_998     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_999     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ input_layer_998[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ input_layer_999[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_757 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ dense_2161[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1291        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_757[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,304</span> │ dropout_1291[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ dense_2162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1292        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │ dropout_1292[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ dense_2163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1293        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span> │ dropout_1293[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ dense_2164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1294        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_1294[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_758 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2165[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_998     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_999     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2161 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │    \u001b[38;5;34m590,592\u001b[0m │ input_layer_998[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ input_layer_999[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_757 (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ dense_2161[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1291        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lambda_757[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2162 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │     \u001b[38;5;34m12,304\u001b[0m │ dropout_1291[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m64\u001b[0m │ dense_2162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1292        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2163 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │        \u001b[38;5;34m340\u001b[0m │ dropout_1292[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │         \u001b[38;5;34m80\u001b[0m │ dense_2163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1293        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2164 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m336\u001b[0m │ dropout_1293[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m64\u001b[0m │ dense_2164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1294        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2165 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_1294[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_758 (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_2165[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,797</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m603,797\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,693</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m603,693\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> (416.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m104\u001b[0m (416.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.exec_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_train, pearson_val, pearson_test = a.train(num_epochs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757942345458769 0.4161434099970364 0.46045058558859026\n"
     ]
    }
   ],
   "source": [
    "print(pearson_train, pearson_val, pearson_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Correlación de Pearson (baseline-train): 0.3534391395435749\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Correlación de Pearson (baseline-validation): 0.07699755710073927\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Correlación de Pearson (baseline-test): 0.062160707942908074\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def compute_pearson(x_, y_):\n",
    "    # Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "    y_pred = a.exec_model.predict(x_)\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    correlation, _ = pearsonr(y_pred.flatten(), y_.flatten())\n",
    "    return correlation\n",
    "print(f\"Correlación de Pearson (baseline-train): {compute_pearson(a.x_train, a.y_train)}\")\n",
    "print(f\"Correlación de Pearson (baseline-validation): {compute_pearson(a.x_val, a.y_val)}\")\n",
    "print(f\"Correlación de Pearson (baseline-test): {compute_pearson(a.x_test, a.y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'SIMILARITY', 'score': 2.1183004307689126}, {'label': 'SIMILARITY', 'score': 2.179974932297432}, {'label': 'SIMILARITY', 'score': 0.9511617858568939}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "from scipy.special import logit\n",
    "\n",
    "model = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "\n",
    "def prepare(sentence_pairs):\n",
    "    sentence_pairs_prep = []\n",
    "    for s1, s2 in sentence_pairs:\n",
    "        sentence_pairs_prep.append(f\"{tokenizer.cls_token} {s1}{tokenizer.sep_token}{tokenizer.sep_token} {s2}{tokenizer.sep_token}\")\n",
    "    return sentence_pairs_prep\n",
    "\n",
    "sentence_pairs = [(\"El llibre va caure per la finestra.\", \"El llibre va sortir volant.\"),\n",
    "                  (\"M'agrades.\", \"T'estimo.\"),\n",
    "                  (\"M'agrada el sol i la calor\", \"A la Garrotxa plou molt.\")]\n",
    "\n",
    "predictions = pipe(prepare(sentence_pairs), add_special_tokens=False)\n",
    "\n",
    "# convert back to scores to the original 0 and 5 interval\n",
    "for prediction in predictions:\n",
    "    prediction['score'] = logit(prediction['score'])\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pairs = [(e[\"sentence1\"], e[\"sentence2\"]) for e in dataset[\"train\"]]\n",
    "y_train = [e[\"label\"] for e in dataset[\"train\"]]\n",
    "input_pairs_val = [(e[\"sentence1\"], e[\"sentence2\"]) for e in dataset[\"validation\"]]\n",
    "y_val = [e[\"label\"] for e in dataset[\"validation\"]]\n",
    "input_pairs_test = [(e[\"sentence1\"], e[\"sentence2\"]) for e in dataset[\"test\"]]\n",
    "y_test = [e[\"label\"] for e in dataset[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación de Pearson (baseline-test): 0.781988582023819\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_pearson(input, y):\n",
    "    # Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "    predictions = pipe(prepare(input), add_special_tokens=False)\n",
    "\n",
    "    for prediction in predictions:\n",
    "        prediction['score'] = logit(prediction['score'])\n",
    "\n",
    "    y_pred = np.array([pred['score']for pred in predictions])\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    correlation, _ = pearsonr(y_pred.flatten(), np.array(y).flatten())\n",
    "    return correlation\n",
    "\n",
    "print(f\"Correlación de Pearson (baseline-test): {compute_pearson(input_pairs_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearman(input, y):\n",
    "    # Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "    predictions = pipe(prepare(input), add_special_tokens=False)\n",
    "\n",
    "    for prediction in predictions:\n",
    "        prediction['score'] = logit(prediction['score'])\n",
    "\n",
    "    y_pred = np.array([pred['score']for pred in predictions])\n",
    "    # Calcular la correlación de Spearman entre las predicciones y los datos de prueba\n",
    "    correlation, _ = spearmanr(y_pred.flatten(), np.array(y).flatten())\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pearson = compute_pearson(input_pairs, y_train)\n",
    "val_pearson = compute_pearson(input_pairs_val, y_val)\n",
    "test_pearson = compute_pearson(input_pairs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9474290525726241 0.7522604466926754 0.781988582023819\n"
     ]
    }
   ],
   "source": [
    "print(train_pearson, val_pearson, test_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spearman = compute_spearman(input_pairs, y_train)\n",
    "val_spearman = compute_spearman(input_pairs_val, y_val)\n",
    "test_spearman = compute_spearman(input_pairs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614333116067086 0.7319414248170184 0.7993360636317496\n"
     ]
    }
   ],
   "source": [
    "print(train_spearman, val_spearman, test_spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Universitat\\4rt Quatri\\PLH\\Practica4\\word-embeddings\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.063855677843094, 2.236715853214264, 0.8875995874404907]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = \"pauhidalgoo/finetuned-sts-roberta-base-ca-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Use mean pooling to get sentence embeddings\n",
    "    return embeddings\n",
    "\n",
    "def calculate_similarity(sentence_pairs):\n",
    "    similarities = []\n",
    "    for s1, s2 in sentence_pairs:\n",
    "        emb1 = get_embeddings([s1])\n",
    "        emb2 = get_embeddings([s2])\n",
    "        sim = cosine_similarity(emb1, emb2)[0][0]\n",
    "        similarities.append(sim*5)\n",
    "        \n",
    "    return similarities\n",
    "\n",
    "# Example sentence pairs\n",
    "sentence_pairs = [(\"El llibre va caure per la finestra.\", \"El llibre va sortir volant.\"),\n",
    "                  (\"M'agrades.\", \"T'estimo.\"),\n",
    "                  (\"M'agrada el sol i la calor\", \"A la Garrotxa plou molt.\")]\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = calculate_similarity(sentence_pairs)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación de Pearson (baseline-test): 0.742854611886582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_pearson(input, y):\n",
    "    # Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "    predictions = calculate_similarity(input)\n",
    "\n",
    "\n",
    "    y_pred = np.array(predictions)\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    correlation, _ = pearsonr(y_pred.flatten(), np.array(y).flatten())\n",
    "    return correlation\n",
    "\n",
    "print(f\"Correlación de Pearson (baseline-test): {compute_pearson(input_pairs_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilitzant el CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # Use mean pooling to get sentence embeddings\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación de Pearson (baseline-test): 0.7146615222274435\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_pearson(input, y):\n",
    "    # Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "    predictions = calculate_similarity(input)\n",
    "\n",
    "\n",
    "    y_pred = np.array(predictions)\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    correlation, _ = pearsonr(y_pred.flatten(), np.array(y).flatten())\n",
    "    return correlation\n",
    "\n",
    "print(f\"Correlación de Pearson (baseline-test): {compute_pearson(input_pairs_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TextSimilarity(model=model, dataset=dataset, mode=\"roberta-hugging\", pretrained=False, cls=False, remap=True, trainable=True, tokenizer = tokenizer, dict_size=1000000, recalculate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.define_model(id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_train, pearson_val, pearson_test, _, _, _= a.train(num_epochs=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
